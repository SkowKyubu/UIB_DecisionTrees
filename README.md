# Implementing Decision Trees Project Overview

## Project Summary
This project involves the implementation and evaluation of a decision tree learning algorithm from scratch. The algorithm is developed to construct decision trees for classification tasks, with features including entropy and information gain calculations, Gini index implementation, and reduced-error pruning.

## Contents
The project is structured as follows:

1. Implement a Decision Tree Learning Algorithm, from Scratch
- **Node and Tree Class**: Object-oriented implementation of decision tree nodes and the decision tree itself.
- **Entropy and Information Gain**: Calculation of entropy and information gain for splitting criteria.
- **Building the Tree**: Recursive function to construct the decision tree based on information gain.

2. Add Gini Index
- Implementation of Gini index as an alternative impurity measure.
3. Add Reduced-Error Pruning
- Recursive function to prune the decision tree and improve generalization.
4. Evaluatation of the Algorithm
- Loading and splitting the dataset for training and testing.
- Training the decision tree and evaluating its accuracy.
- Visualizing accuracy and computation time.

5. Compare to an Existing Implementation
- Comparison of the implemented decision tree with scikit-learn's decision tree implementation.
- Visualizing accuracy and computation time comparisons.

## Purpose
The purpose of this project is to gain a deeper understanding of decision tree learning algorithms by implementing them from scratch. By comparing the performance and efficiency of the custom implementation with an existing one from a widely-used machine learning library like scikit-learn, insights into algorithmic optimization and real-world applicability are gained.





